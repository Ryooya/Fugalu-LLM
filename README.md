# Fugaku-LLMを使ってみよう

>東京工業大学 学術国際情報センターの横田理央教授の研究チームと東北大学 大学院情報科学研究科の坂口慶祐准教授、富士通
>株式会社 人工知能研究所の白幡晃一シニアプロジェクトディレクター、理化学研究所 のMohamed Wahib（モハメド・ワヒブ）
>チームリーダー、名古屋大学 大学院工学研究科の西口浩司准教授、株式会社サイバーエージェント AI事業本部AI Labの佐々木
>翔大リサーチサイエンティスト、Kotoba Technologies Inc. の小島熙之CEOは、理化学研究所のスーパーコンピュータ「富
>岳」を用いて学習した日本語能力に優れた大規模言語モデル（注1）「Fugaku-LLM」を2024年5月10日に公開した。
  
引用：Fujitsu-"スーパーコンピュータ「富岳」で学習した大規模言語モデル「Fugaku-LLM」を公開
"[https://pr.fujitsu.com/jp/news/2024/05/10.html]  
みたいですヨ。

## モデルの情報

* **Developed by**: Fugaku-LLM
* **Model type**: GPT-2
* **Language(s)**: Japanese, English
* **Library**: [DeepSpeedFugaku](https://github.com/Fugaku-LLM/DeepSpeedFugaku) 
* **Tokenizer**: [llm-jp-tokenizer](https://github.com/llm-jp/llm-jp-tokenizer), code10k_en20k_ja30k of v2.2
* **License**: Fugaku-LLM Terms of Use

### リンク
- モデル:[https://huggingface.co/Fugaku-LLM/Fugaku-LLM-13B]
- ソースコード:[https://github.com/Fugaku-LLM/DeepSpeedFugaku]

## つかいかた
３つあるモデルのうち、instructionモデルの使い方について記載しておきます。  
1. 使いたいモデルのhuggingfaceページにとび、利用規約に同意する。(10条しかないので目を通すのが吉)
1. このgitのクローンをする
1. パッケージのインストール
1. main.pyを動かして、モデルのインストール・量子化・推論
1. 出力

って流れです。まず１から順にみてきます。

### 1. 利用規約の同意
これは以下のURLにアクセスして、上から２つ目のinstructモデルをみる。  
[https://huggingface.co/Fugaku-LLM]  
すると、なんか小難しい日本語が並んでる（利用規約）ので、ばーっと読んでボタンをポチってすればおｋです。  
huggingfaceのアカウントが必要なので、その設定も要ります。

### 2. gitのクローンをしよう
(VScodeを使っている前提になります)  
ここで、git関連の説明をするととんでもなく長くなるので、以下のurlから情報を拾って頑張ってみてください。  
[とりあえず周りと仕事ができるGitHub入門](https://qiita.com/konbraphat51/items/8d4907bf02cfff518462)
git関連でわかんなくなったら先生か専攻科生に聞くとよいよ。

### 3. パッケージのインストール

pythonに不慣れな方向けに、参考になるページもおいておきます。  

- [venvで手軽にPythonの仮想環境を構築しよう](https://qiita.com/shun_sakamoto/items/7944d0ac4d30edf91fde)
- [pipの使い方(インストール、ダウンロード)](https://qiita.com/kilowatt/items/808a35d9f13ad8374e30)
- [PyTorchのインストール](https://qiita.com/thinknee/items/0c0c466928356c9a55af)

検索で使えるキーワード「VScode 仮想環境　作り方」「pip install やり方」「venv バージョン指定」とかですかね。。  
(自分の所感なのですが、個人のブログとかのほうがわかりやすかったりします。)

実際の手順については、Pytorchを自身の環境に合わせてインストールしていただき、そのあとrequirement.txtをpip installしていただければおｋです。一応自身の環境を置いておきます。Pythonのバージョンは`3.10.11`です。
```
accelerate==0.30.1
bitsandbytes==0.43.1
certifi==2024.2.2
charset-normalizer==3.3.2
colorama==0.4.6
filelock==3.13.1
fsspec==2024.2.0
huggingface-hub==0.23.0
idna==3.7
intel-openmp==2021.4.0
Jinja2==3.1.3
MarkupSafe==2.1.5
mkl==2021.4.0
mpmath==1.3.0
networkx==3.2.1
numpy==1.26.3
packaging==24.0
pillow==10.2.0
psutil==5.9.8
PyYAML==6.0.1
regex==2024.5.15
requests==2.31.0
safetensors==0.4.3
sympy==1.12
tbb==2021.11.0
tokenizers==0.19.1
torch==2.3.0+cu121
torchaudio==2.3.0+cu121
torchvision==0.18.0+cu121
tqdm==4.66.4
transformers==4.40.2
typing_extensions==4.9.0
urllib3==2.2.1
```

### 3. つかってみよう
実際に実行してみましょう。推論時間はけっこー長めです。（2分超えることも。。。）  
ターミナルに`python.exe .\fugaku_main.py`打ち、動かしてみると。。。。  
```
以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。

### 指示:
スーパーコンピュータ「富岳」の名前の由来を教えてください。

### 応答:
「富岳」は日本のスーパーコンピュータの名前で、「富士山」を意味する。この名前は、日本のスーパーコンピュータの開発を支援し
た理化学研究所と富士通の両社にゆかりのあるもので、両社はともに日本の富士山周辺に拠点を置いている。
経過時間: 270.2403988838196
```
出ましたね。ただ、経過時間がものすごい長いっす。  
そこで、量子化をしてみようってのが'quantized_fugaku_main.py'です。
量子化に関してはぐぐってみてね。(簡単に言えばパラメータの端数を切り捨ててデータ量を少なくする方法)  

### 4. 改良版をつかってみよう
`bitsandbytes`を使って４ビット量子化を試してみましょう。
ターミナルに`python.exe .\quantized_fugaku_main.py`打ち、動かしてみると。。。。  
```
以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。

### 指示:
スーパーコンピュータ「富岳」の名前の由来を教えてください。

### 応答:
「富岳」は日本のスーパーコンピュータの名前で、富士山の異名でもあります。この名前は、日本のスーパーコンピュータの開発を支 援した理化学研究所と富士通の両社が、日本で最も高い山である富士山にちなんだもので、スーパーコンピュータが日本の科学と産業 のために優れたパフォーマンスを発揮することを願っています。
経過時間: 38.300966024398804
```
約７倍早く推論できるようになりましたね！よきかな～  

## いろいろ推論させてみよう
ここでは推論結果の例を載せてきます。
### コーディング
````
下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。

### 指示:
入力された金額を金種別に分類するプログラムをPythonで作成してください。

### 応答:
金種別に入金額を分類するには、マネーグラム表を使うことができます。マネーグラム表は、各金種の金額を行と列に配置した表です 。マネーグラム表を使って入金を分類するには、以下の手順に従います：

入力金額のデータを、行と列に金額を配置する形式でマネーグラム表に入力します。

各行の金額を、その行にある金種の数で割った値を計算します。

列の合計を計算し、その結果を列の値の数で乗算して、各金種の合計を求めます。

金種の合計を計算し、その結果を合計する。

以下は、Pythonでマネーグラム表を使って入金を分類する方法を示すコード例である：
```
# 入力金額を表すマネーグラム表を作成する
income_table = [[0, 0.05, 0.10, 0.20],
                [0, 0.05, 0.10, 0.20],
                [0, 0.05, 0.10, 0.20],
                [0, 0.05, 0.10, 0.20]].

# 行の金額をその行にある金種の数で割る
def row_percentage(row):
    return sum(row) / len(row)

# 列の合計を計算し、列値の数で乗算する
def col_total(col)：
    return sum(col) * len(col)

# 金種別の合計を計算する
def total_income(income_table)：
    total = 0
    for row in income_table：
        total += row_percentage(row)
    return total

# プログラムを呼び出す
print(total_income(income_table))
```
この例では、income_table をマネーグラム表として入力として受け取り、total_income を呼び出して入金額の合計を表示します。row_percentage と col_total はマネーグラム表の各行と列を処理する関数です。金種別の合計を計算するために使用されます。        
経過時間: 52.02008605003357
````
関数定義の最後のコロン（:）が全角になっていて、リストの最後の要素の後に不要なピリオド以外はコーディングできてる。  
しかし、欲しかったプログラムは「入力された金額を1000円札、500円玉、100円玉、10円玉の各金種に分類し、その枚数を数えて出力する」ものだったので、ちょっと違うな～～と感じた。GPT3.5だとその意図を読み取って作ってくれていたので、プロンプトエンジニアリングをしなきゃですね～～  
指示を明確にしたものを以下に示します
````
以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。

### 指示:
力された金額を1000円札、500円玉、100円玉、10円玉の各金種に分類し、その枚数を数えて出力するプログラムをPythonで作成してく ださい。

### 応答:
もちろんです！ここに、硬貨の枚数を数え、各硬貨の合計金額を表示するPythonプログラムがあります。
```
import sys

def count_coins(coins, amount):
    if amount == 1000:
        return [1, 0, 0, 0]
    if amount == 500:
        return [0, 1, 0, 0]
    if amount == 100:
        return [0, 0, 1, 0]
    if amount == 10:
        return [0, 0, 0, 1]

if len(sys.argv) != 2:
    print("硬貨の合計金額を入力してください: 1000円")
    exit(1)

amount = int(sys.argv[1])

coins = [1000, 500, 100, 10]
total = 0

for i in range(4):
    total += coins[i] * count_coins(coins, amount - coins[i])[i]

print(f"{amount}円の合計金額は{total}円です。")
```
このプログラムは、与えられた金額から各硬貨の枚数を計算し、硬貨の合計金額を表示します。実行するには、`python count_coins.py 1000`と入力し、硬貨の合計金額を1000円に設定します。
経過時間: 52.57761883735657
````
プログラム内で count_coins 関数が呼び出されているものの、その結果を適切に使ってないですね。。。  
量子化の影響もあったりするので要検証です。

### 人文社会系
公式のプレスリリースから引用すると、
> 国産かつ独自のデータで学習を行っているオープンなモデルの中では日本語ベンチマークJapanese MT-Bench（注5）で最高性能を達成し、特に人文社会系のタスクでは高いベンチマーク性能を発揮する。
ってあるので、人文社会系を推論させてみよう。 
- task1 : "経済成長率、消費者物価指数、失業率などの経済指標と日本銀行の金融政策との関係性を説明してください。その経済指標に影響を与える主な政策手段を示し、それぞれの効果について考察してください。また、それらの内容を5歳の子供に教えるとしたら、どのように説明しますか？"
- task2 : "論理的な書き方で論議を評価するための5つの主要な原則を説明してください。リスト化した原則を使用して、論議を評価するための具体的な証拠について議論し、その証拠が論議を弱めるか強化するかを説明してください。"

この2つで能力を測ってみよう。２つとも、Japanese MT-Bench内のそれぞれ`question_id = 21, 27`のものをそのまま引用しています。  

Japanese MT-Benchは[このページ](https://github.com/Stability-AI/FastChat/blob/jp-stable/fastchat/llm_judge/data/japanese_mt_bench/question.jsonl)に中身が乗ってます。

#### task1の結果
```
以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。

### 指示:
('経済成長率、消費者物価指数、失業率などの経済指標と日本銀行の金融政策との関係性を説明してください。その経済指標に影響を 与える主な政策手段を示し、それぞれの効果について考察してください。', 'また、それらの内容を5歳の子供に教えるとしたら、どのように説明しますか？')

### 応答:
経済成長率、消費者物価指数、失業率などの経済指標は、日本銀行（BOJ）の金融政策に大きな影響を与えます。これらの指標は、経済が健全で安定した成長を続けているかどうかを判断するために使用されます。金融政策は経済指標に影響を与え、経済活動の変化に対 応するために日本銀行によって実施される。

経済指標に影響を与える主な政策手段には、以下のようなものがある：

金融政策：金融政策：日本銀行は、通貨供給量の増加、金利の調整、国債の購入などの方法によって、経済活動を刺激または抑制する ために金融政策を実施する。

インフレ目標：日本銀行は、消費者物価指数（CPI）の前年比上昇率2％の「物価安定の目標」を2％の「インフレ目標」に置き換えた。CPIはインフレの指標として使用され、金融政策の指針となる。

量的金融緩和（QFY）：日本銀行は、経済活動を刺激するために、国債の購入などの方法で大量の資金を供給することがある。        

ターゲティング・ポリシー：日本銀行は、特定の経済指標の達成を目指し、その目標に沿った金融政策を実施することがある。例えば 、日本銀行は、2％のインフレ目標を達成するために、インフレ率の低下を目指して金融政策を実施することがある。

フォワードガイダンス：日本銀行は、将来の金融政策に対する指針を提供するため、経済指標を考慮するフォワードガイダンスを実施 することがある。

これらの政策手段は、経済指標に影響を与えるさまざまな効果をもたらす。金融政策は通貨供給量や金利に影響を与え、インフレ目標 は物価や経済成長率に影響を与え、量的金融緩和は経済活動に影響を与え、フォワードガイダンスは将来の金融政策の指針となる。   

5歳の子供にこのトピックを説明するには、以下のように説明するとよい：

経済は成長し、変化する生き物です。日本銀行は、これらの変化を監視し、経済がその健全性と安定性を保つために必要な金融政策を 実施する責任がある。金融政策とは、お金を増やしたり減らしたり、金利を変えたりすることで、経済を刺激したり抑制したりする方 法です。インフレ率や失業率などの経済指標は、日本銀行が金融政策を調整するための重要な指標です。これらの指標は、私たちの生 活に影響を与える変化を示しています。私たちが賢く責任ある消費者であるためには、これらの指標に注意を払い、それらが私たちの 経済にどのような影響を与えるかを理解することが重要です。
経過時間: 51.668935775756836
```

いやすごいかも？  言語化能力はほかの日本語特化LLMモデルより明らかに高いか。
#### task2の結果
```
以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。

### 指示:
('論理的な書き方で論議を評価するための5つの主要な原則を説明してください。', 'リスト化した原則を使用して、論議を評価するための具体的な証拠について議論し、その証拠が論議を弱めるか強化するかを説明してください。')

### 応答:
1.議論を評価するには、その論点が主要な問題をどの程度解決しているかを見ればよい。
2.論点が主要な問題をどの程度解決しているかを評価するには、その論点が解決しようとしている主要な問題を定義し、その問題が議 論されているかどうかを見ればよい。
3.証拠は論議を支えるものでなければならない。証拠が多ければ多いほど、論議は強くなる。
4.証拠は、論点を支えるために適切な種類のものでなければならない。証拠が主観的なものであったり、偏ったものであったりする場 合、その論議は弱くなる。
5.論点は、それが実際に主要な問題を解決するものであれば、強い論議となる。

証拠
* 気候変動は主要な問題である。
* 気候変動は現実の問題である。
* 二酸化炭素排出量を削減することは、気候変動を緩和するために重要である。
* 二酸化炭素排出量を削減することは、気候変動を緩和するために重要である。
* 二酸化炭素排出量を削減することは、気候変動を緩和するために重要である。
* 気候変動は主要な問題である。

結論
この論議は、主要な問題である気候変動をどの程度解決しているか。
この論議は、主要な問題である気候変動を解決するには不十分である。なぜなら、議論されているのは緩和に関することだけであり、 防止に関することは議論されていないからである。
経過時間: 46.74233150482178
```
具体例になると繰り返し同じことを述べてしまうし、結論の要約に関しては不十分だと考えられる。だが、5つの主要な原則はかなりよいね。


## まとめ
- Elyza, Swallowと比較して推論時間は長めか
- 計算・コーディングは同等かそれ以下になるが、人文社会系などのチャットボットとして必要である言語化能力に関してはChatgpt-3.5と遜色ない性能か？
- 使用されたデータがクリーンなものだと保証されているので、安心して使えそう。
- 60%が日本語データとのことなので、ElyzaやSwallowと比べたとき日本語タスクは絶対つよい。（Llamaベースなので）